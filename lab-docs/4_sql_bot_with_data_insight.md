# Support for SQL Bot with Data Insight

The previous chatbot is able to generate SQL queries based on the user input. Now, let's upgrade it to execute the generated SQL query and display the results. But it sounds like a robot, right? Let's make it more human-like by adding insights from the data.

## Add insights from the data

A way to make the chatbot is ... generate output more like a human. We can use the LLM to derive insights from the data.

## Create a new bot

First, let's copy the `sql_chatbot_with_tweaks.py` to `sql_chatbot_with_data_insight.py` and update the class name to `SQLChatbotWithDataInsight`.

We can reuse most of the code from the previous step, but we need to add the LLM to generate insights from the data.

In order to do that, we need to call the LLM API

We have prepared a small wrapper class to call the LLM API. You can find the `get_openai_output` in the [utils.py](../utils.py) file.

## Call the LLM API to get insights

Let's add a new method to the `SQLChatbotWithDataInsight` class to call the LLM API and get insights from the data.

```python
    @staticmethod
    def get_data_insights(user_query, df):
        prompt = (f"Given the following data:\n{str(df.to_csv())[:10240]}, \n and user_ask={user_query}. "
                  f"What insights can you provide? Summarize the result within 50 words. Make sure the output is concise and punchy, break down long paragraphs into parts. Output:")

        return get_openai_output(prompt)
```

This is a simple method that takes the user query and the data frame as input and generates a prompt for the LLM API. The prompt is generated by concatenating the user query and the data frame. The prompt is then passed to the `get_openai_output` method to get the insights from the data.

## Update create_answer method

```python
    def create_answer(self, user_query):
        waii = self.initialize_waii_client_if_needed()

        # now based on the user query, we generate the answer
        generated_query = waii.query.generate(QueryGenerationRequest(ask=user_query, tweak_history=self._get_tweaks()))

        self._add_tweaks(generated_query.query, user_query, generated_query.is_new)
        
        # get run query result
        df = generated_query.run().to_pandas_df()
        
        ### ^^^ above this, the code is the same as the previous step ^^^ ###
        ### Following code is added to get insights from the data ###

        insights = self.get_data_insights(user_query, df)

        # display with formatting (sql, steps, data)
        display_answer(AssistantOutput(messages=[
            AssistantMessage(content=df, type=AssistantMessageType.Data),
            AssistantMessage(content=insights, type=AssistantMessageType.Text),
        ]), 'assistant', True)
```

In the `create_answer` method, we call the `get_data_insights` method to get insights from the data. We pass the user query and the data frame generated by the generated query to the `get_data_insights` method. The insights are then displayed along with the data frame.

You may also noticed that we have removed SQL and detailed steps from the output. We are only displaying the data and insights from the data.

## Run it

You can use the received OpenAI API key (From Waii Team) to run the chatbot with data insights. You can run the chatbot using the following command:

```bash
WAII_API_KEY='...' WAII_API_SERVER_URL="..." DATABASE_CONNECTION_KEY='...' OPENAI_API_KEY='...' LOG_LEVEL=DEBUG streamlit run main.py
```

Now you can ask question like `what is the avg revenue for movies`, you will get a table, and insights like
```
The average revenue for movies is approximately $277.75 million. 
This figure indicates a significant earning potential in the 
film industry, highlighting its lucrative nature.
```

## Make it streaming

You may noticed the insight is output as a whole, not word-by-word like what you saw on chatgpt. This is because we didn't enable streaming for the openai output. 

We can use stream output and streamlit to enable the streaming.

You just need to update two parts: 

1. Call the `get_openai_output` with `stream=True` in `get_data_insights` method
2. When display the answer, you can use TextStream type instead of Text.

```python
    display_answer(AssistantOutput(messages=[
        AssistantMessage(content=df, type=AssistantMessageType.Data),
        AssistantMessage(content=insights, type=AssistantMessageType.TextStream), # <-- Instead of Text 
    ]), 'assistant', True)
```

If you run it again, you will see the insights are streaming word-by-word just like ChatGPT.

## Bonus: update the prompt

If you want to make the insights more human-like, you can update the prompt in the `get_data_insights` method. You can play with different prompts to get different insights. 

For example you can force the model to output different language like: `... always use Chinese to describe the data insights ...`

After you get something interesting, please share the result with the Slack channel.

## Final source code

You can check the full source code of the SQL bot with data insights at [bots/sql_chatbot_with_data_insight.py](../bots/sql_chatbot_with_data_insights.py)